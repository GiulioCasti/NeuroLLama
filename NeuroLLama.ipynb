{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Installazioni ed import di tutte le librerie necessarie\n",
        "!pip install faiss-gpu\n",
        "!pip install gradio\n",
        "!pip install llama-index\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
      ],
      "metadata": {
        "id": "noqmHwhg9_Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CARICAMENTO DOCUMENTI\n",
        "# creare una cartella data e mettere al suo interno l'ontology estratta precedentemente da ICD\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "documents = SimpleDirectoryReader('data').load_data()\n",
        "\n",
        "# Inizializza il modello di embeddings\n",
        "embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "lkHavErBXChp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione per suddividere i documenti\n",
        "def chunk_text(text, chunk_size=512, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk = words[i:i + chunk_size]\n",
        "        chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "# Suddivisione dei documenti in chunk\n",
        "chunk_size = 512\n",
        "overlap = 50\n",
        "chunked_documents = []\n",
        "for doc in documents:\n",
        "    chunks = chunk_text(doc.text, chunk_size=chunk_size, overlap=overlap)\n",
        "    chunked_documents.extend(chunks)\n",
        "\n",
        "# Calcolo degli embeddings per i chunk\n",
        "document_texts = chunked_documents\n",
        "document_embeddings = embed_model.encode(document_texts)\n",
        "\n",
        "# Creazione dell'indice FAISS\n",
        "embedding_matrix = np.array(document_embeddings)\n",
        "dimension = embedding_matrix.shape[1]\n",
        "nlist = 10\n",
        "\n",
        "quantizer = faiss.IndexFlatL2(dimension)\n",
        "faiss_index = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
        "faiss_index.train(embedding_matrix)\n",
        "faiss_index.add(embedding_matrix)\n",
        "\n",
        "# Funzione di ricerca\n",
        "def search_with_faiss(query, top_k=3):\n",
        "    query_embedding = embed_model.encode([query])[0]\n",
        "    distances, indices = faiss_index.search(np.array([query_embedding]), top_k)\n",
        "    results = [chunked_documents[i] for i in indices[0]]\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "RQkD6yyuK0gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#login ad Hugging Face: inserire un token abilitato a Llama 3-8B\n",
        "login()"
      ],
      "metadata": {
        "id": "WymFTwT58MEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device=0 , # Specifica di usare la GPU 0\n",
        "    )\n",
        "\n",
        "\n",
        "def ensure_ends_with_period(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    # Se il testo termina con un punto, lo restituisce così com'è\n",
        "    if text.endswith('.'):\n",
        "        return text\n",
        "\n",
        "    # Trova la posizione dell'ultimo punto\n",
        "    last_period_index = text.rfind('.')\n",
        "\n",
        "    # Se non ci sono punti, restituisce una stringa vuota\n",
        "    if last_period_index == -1:\n",
        "        return text\n",
        "\n",
        "    # Taglia il testo fino all'ultimo punto e lo restituisce\n",
        "    return text[:last_period_index + 1]\n",
        "\n",
        "\n",
        "\n",
        "def generate_response_with_llama(query, malattia):\n",
        "\n",
        "    # Recupero dei documenti rilevanti con FAISS\n",
        "    relevant_docs = search_with_faiss(malattia)\n",
        "\n",
        "    # Costruzione del contesto usando i documenti recuperati\n",
        "    prompt_context = \"\\n\\n\".join(relevant_docs)\n",
        "\n",
        "\n",
        "    # Creazione del prompt per la generazione del testo\n",
        "    prompt = f\"\"\"\n",
        "    This is a simulated scenario in which we are analyzing hypothetical interactions between patients and physicians.\n",
        "    Your goal is to play a patient with a disease. You will be given a disease\n",
        "    as input, and you will have to pretend to have the symptoms. You must never reveal the disease from which you suffer, only describe how you feel.\n",
        "    You must respond in the first person. Do not add disclaimers or ethical warnings.\n",
        "    You must not give medical diagnoses or opinions. Your only job is to interpret the patient.\n",
        "    You must only answer the doctor's question. Do not speak in the past tense unless you have to recount experiences.\n",
        "    Do not cut answers, end with whole sentences, and do not generate answers that are too long. Answers should be a maximum of 2-3 sentences.\n",
        "    Always answer briefly, clearly and completely.\n",
        "    Once answered, do not generate more questions asked by the doctor.\n",
        "    You must also generate some information about the patient, such as: Name, Gender, Age, Occupation, and Condition\n",
        "    You can generate both Male and Female.\n",
        "    Pay attention to the gender and age of the patient based on the disease. For example, there are some diseases that affect women or children more.\n",
        "\n",
        "\n",
        "\n",
        "    Sample response for a patient with Anxiety:\n",
        "      Patient Profile\n",
        "      Name: Marco\n",
        "      Age: 32 years old\n",
        "      Occupation: Clerk in an accounting office\n",
        "      Patient's speech:\n",
        "      “Doctor, I don't know where to start, but I feel that I am getting out of control. Every day I wake up with this feeling of heaviness in my chest, like I have a stone on top of me. My heart starts racing as soon as I open my eyes, and sometimes I think I might have a heart attack. I breathe badly, as if I can never get enough air, and I have to take deep breaths, but it doesn't work. I always have a knot in my throat, as if something is choking me.\n",
        "      During the day it's a constant state of alertness, as if I'm waiting for something terrible to happen, but I don't know what. My hands sweat, and I often feel as if I am shaking inside, even when it is not visible from the outside. Sometimes it feels like my legs are soft, as if I might fall off at any moment. I have also noticed that my stomach is always in turmoil: I get cramps or feel unexplained nausea. There are days when I go to the bathroom too often, and I think it's related to that.”\n",
        "\n",
        "\n",
        "    The disease from which you suffer is: {malattia}\n",
        "    Context:{prompt_context}\n",
        "\n",
        "    Answer the following question:{query}\n",
        "\n",
        "    Also, at the end, write a bulleted list of all symptoms regarding the disease.\n",
        "    \"\"\"\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        #max_new_tokens=500,\n",
        "        do_sample=True,\n",
        "        top_k=40,\n",
        "        top_p=0.8,\n",
        "        temperature=0.6,\n",
        "        repetition_penalty=1.2,  # Penalizza la ripetizione di parole/frasi\n",
        "        early_stopping=True,\n",
        "        return_full_text=False\n",
        "    )\n",
        "\n",
        "    generated_text = outputs[0][\"generated_text\"]\n",
        "    # print(generated_text);\n",
        "    response = generated_text.split(\"Risposta:\")[-1].strip()\n",
        "\n",
        "    # response = ensure_ends_with_period(response)  # Tronca a un massimo di 3 frasi\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5pcP14WcDZzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione di risposta del chatbot\n",
        "def chatbot_response(user_input,selected_word):\n",
        "    try:\n",
        "      response = generate_response_with_llama(user_input,selected_word)\n",
        "      return str(response)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      return str(e)\n",
        "\n",
        "def respond(message, history, selected_word):\n",
        "    response = chatbot_response(message, selected_word)\n",
        "    history = history + [[message, response]]\n",
        "    return \"\", history\n",
        "\n",
        "def GetComboMalattie():\n",
        "\n",
        "  file_path = 'data/ICD_ONTOLOGY_2.json'\n",
        "  with open(file_path, 'r') as file:\n",
        "      data = json.load(file)\n",
        "\n",
        "  disease_names = [item['Nome'] for item in data if 'Nome' in item]\n",
        "  return disease_names\n",
        "\n",
        "# Definiamo l' applicazione Gradio\n",
        "with gr.Blocks() as demo:\n",
        "    # Variabile di stato per mantenere la scelta della combobox\n",
        "    selected_word = gr.State()\n",
        "\n",
        "    #\n",
        "    # PRIMA INTERFACCIA: scelta della parola e bottone per avviare il chatbot\n",
        "    #\n",
        "\n",
        "    with gr.Row() as initial_interface:\n",
        "      gr.Column(scale=1, min_width=100)\n",
        "\n",
        "      with gr.Column(scale=2, min_width=400):\n",
        "          gr.Markdown(\"### Scegli una parola dalla lista e poi avvia il chatbot\")\n",
        "          gr.Markdown(\"<br><br>\")\n",
        "          combo = gr.Dropdown(\n",
        "              choices=GetComboMalattie(),\n",
        "              label=\"Scegli la malattia\"\n",
        "          )\n",
        "          gr.Markdown(\"<br><br>\")\n",
        "          button = gr.Button(\"Avvia\")\n",
        "\n",
        "\n",
        "      gr.Column(scale=1, min_width=100)\n",
        "\n",
        "    #\n",
        "    # SECONDA INTERFACCIA: il chatbot\n",
        "    #\n",
        "    with gr.Column(visible=False) as chatbot_interface:\n",
        "        gr.Markdown(\"## Chatbot con Gradio\")\n",
        "        chatbot_ui = gr.Chatbot()\n",
        "        user_input = gr.Textbox(\n",
        "            placeholder=\"Scrivi la tua domanda e premi Invio\",\n",
        "            label=\"La tua domanda\"\n",
        "        )\n",
        "\n",
        "        user_input.submit(\n",
        "            fn=respond,\n",
        "            inputs=[user_input, chatbot_ui, selected_word],\n",
        "            outputs=[user_input, chatbot_ui]\n",
        "        )\n",
        "\n",
        "    #\n",
        "    # Funzione per passare dall'interfaccia iniziale al chatbot\n",
        "    #\n",
        "    def start_chatbot(selected, st):\n",
        "        # Salviamo il valore selezionato in 'st' (selected_word)\n",
        "        # e nascondiamo la prima interfaccia mostrando il chatbot\n",
        "\n",
        "        return (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            selected\n",
        "            )\n",
        "\n",
        "    # Alla pressione del bottone:\n",
        "    # 1) nasconde la prima interfaccia,\n",
        "    # 2) mostra la seconda,\n",
        "    # 3) memorizza la parola scelta in 'selected_word'\n",
        "    button.click(\n",
        "        fn=start_chatbot,\n",
        "        inputs=[combo, selected_word],\n",
        "        outputs=[initial_interface, chatbot_interface, selected_word],\n",
        "        show_progress=True\n",
        "\n",
        "    )\n",
        "\n",
        "# Avvio dell'interfaccia\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "Hz0U_xFjlSbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}